{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_time_series.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSScfsySO3IauTI5AU8rUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucarubini/DeepLearning_quick_introduction/blob/main/demo_time_series/demo_time_series_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demo Serie Temporali (per previsione domanda prodotti)**\n",
        "\n",
        "\n",
        "1.   Definizione delle funzioni e librerie da importare\n",
        "2.   Caricamento e analisi dei dati\n",
        "3.   Definizione e addestramento del modello\n",
        "4.   Test \n",
        "\n"
      ],
      "metadata": {
        "id": "bc0eWUONvGmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definizione delle funzioni e librerie da importare**"
      ],
      "metadata": {
        "id": "7vIPM7FNvQKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importare le librerie necessarie\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BgM2HCEQERDv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test(test_df, filename, model, norm_vector,time_step=1):\n",
        "  \"\"\"\n",
        "  funzione per generare un file di testo che contiene\n",
        "  INPUT\n",
        "   -test_df: DataFrame con contiene per ogni riga t la domanda di prodotto all'istante temporale t\n",
        "   -filename: Nome del file di output in cui memorizzare gli output del modello\n",
        "   -model: Modello per la stima della domanda\n",
        "   -norm_vector: Vettore per la normalizazzione degli output\n",
        "   -time_step(defaul=1): range temporale da prendere in considerazione per generare l'output al tempo t\n",
        "  OUTPUT\n",
        "   -f_out: file che contiene per ogni riga la stima della domanda di ciascun prodotto (l'output del modello)\n",
        "  \"\"\"\n",
        "  n_examples = len(test_df)\n",
        "  n_outputs = n_examples-time_step\n",
        "  n_prods = int(train_max.size/2)\n",
        "  print(f\"Numero di prodotti: {str(n_prods)}\")\n",
        "  print(f\"Numero di output da generare: {n_outputs}\")\n",
        "  print(f\"Output filename: {filename}\")\n",
        "  with open(filename,'w') as f_out:\n",
        "    for i in range(n_outputs):\n",
        "      df_i = test_df[i:i+time_step]\n",
        "      input_i = np.array(df_i)\n",
        "      input_i = np.expand_dims(input_i, axis=0)\n",
        "      out_i = model(input_i)\n",
        "      out_i = out_i * train_max[n_prods:]\n",
        "      f_out.write(\" \".join([str(out_i[0,i].numpy()) for i in range(out_i.shape[1])])+\"\\n\")"
      ],
      "metadata": {
        "id": "708eJt169rkJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_mse(filename,target_df):\n",
        "  \"\"\"\n",
        "  funzione per calcolare l'MSE dat\n",
        "  INPUT\n",
        "   -filename: nome del file che contiene la previsione della richiesta di prodotti, una riga per timestep\n",
        "   -target_df: target della richiesta di prodotti, una riga per timestep. Il formato e' Pandas DataFrame\n",
        "  OUTPUT\n",
        "   -mse_out: (\"mse_$filename\") file che contiene per ogni riga l'MSE di ciascun prodotto\n",
        "   -mse_avg_out: (\"mse_avg_$filename\") file che contiene per ogni riga l'MSE medio di tutti i prodotti\n",
        "  \"\"\"\n",
        "  avg_mse = 0\n",
        "  with open(filename,'r') as f_in, open(f\"mse_{filename}\",'w') as mse_out, open(f\"mse_avg_{filename}\",'w') as mse_avg_out:\n",
        "    for i,line in enumerate(f_in):\n",
        "      tmp_i = [float(x) for x in line.rstrip().split()]\n",
        "      tmp_out = np.array(tmp_i)\n",
        "      out_i = np.array(tmp_out)\n",
        "      tgt_i = np.array(target_df[i,:])\n",
        "      mse_i = ((out_i - tgt_i)**2)\n",
        "      mse_i_mean = mse_i.mean(axis=0)\n",
        "      avg_mse += mse_i_mean\n",
        "      mse_out.write(\" \".join([str(mse_i[i]) for i in range(mse_i.shape[0])])+\"\\n\")\n",
        "      mse_avg_out.write(f\"{mse_i_mean}\"+\"\\n\")"
      ],
      "metadata": {
        "id": "yZHStsvz5Dra"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_avg_mse(filename):\n",
        "  \"\"\"\n",
        "  funzione per calcolare MSE medio\n",
        "  INPUT\n",
        "   -filename: file che contiene l'MSE della stima della richiesta di tutti i prodotti, una riga per timestep\n",
        "  OUTPUT\n",
        "   -out: MSE medio di tutti gli MSE contenuti nel file $filename, e' la media di tutti gli errori medi fatti in test\n",
        "  \"\"\"\n",
        "  out = 0\n",
        "  with open(filename,'r') as f:\n",
        "    for i, num in enumerate(f):\n",
        "        out += float(num.rstrip())\n",
        "  out = out / (i+1)\n",
        "  return out"
      ],
      "metadata": {
        "id": "8LfKJsYA5Eft"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classe per generare le finestre di dati\n",
        "class WindowGenerator():\n",
        "  \"\"\"\n",
        "  Classe per gestire e generare le finestre di dati\n",
        "  INPUT\n",
        "   -input_width: time range per input\n",
        "   -label_width: time range per target\n",
        "   -shift: shift temporale \n",
        "   -train_df: DataFrame di Train\n",
        "   -val_df: DataFrame di Valid\n",
        "   -test_df: DataFrame di Test\n",
        "   -input_columns: nome delle colonne usate per input\n",
        "   -label_columns: nome delle colonne usate per target\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_width,\n",
        "               label_width,\n",
        "               shift,\n",
        "               train_df,\n",
        "               val_df,\n",
        "               test_df,\n",
        "               input_columns=None,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.input_columns = input_columns\n",
        "    if input_columns is not None:\n",
        "      self.input_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(input_columns)}\n",
        "    \n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices (t): {self.input_indices}',\n",
        "        f'Label indices (t): {self.label_indices}',\n",
        "        f'Input column name(s): {self.input_columns}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n",
        "  \n",
        "  def split_window(self, features):\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.input_columns is not None:\n",
        "      inputs = tf.stack(\n",
        "          [inputs[:, :, self.column_indices[name]] for name in self.input_columns],\n",
        "          axis=-1)\n",
        "    if self.label_columns is not None:\n",
        "      labels = tf.stack(\n",
        "          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "          axis=-1)\n",
        "\n",
        "    # Slicing doesn't preserve static shape information, so set the shapes\n",
        "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "  def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "        data=data,\n",
        "        targets=None,\n",
        "        sequence_length=self.total_window_size,\n",
        "        sequence_stride=1,\n",
        "        shuffle=True,\n",
        "        batch_size=32,)\n",
        "    ds = ds.map(self.split_window)\n",
        "    return ds\n",
        "\n",
        "  @property\n",
        "  def train(self):\n",
        "    return self.make_dataset(self.train_df)\n",
        "\n",
        "  @property\n",
        "  def val(self):\n",
        "    return self.make_dataset(self.val_df)\n",
        "\n",
        "  @property\n",
        "  def test(self):\n",
        "    return self.make_dataset(self.test_df)\n",
        "\n",
        "  @property\n",
        "  def example(self):\n",
        "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "    result = getattr(self, '_example', None)\n",
        "    if result is None:\n",
        "      # No example batch was found, so get one from the `.train` dataset\n",
        "      result = next(iter(self.train))\n",
        "      # And cache it for next time\n",
        "      self._example = result\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "t3njqWiwzhuQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_XY(filename, label, shift=0):\n",
        "  \"\"\"\n",
        "  INPUT\n",
        "   -filename: nome del file che contiene le domande per ciascun prodotto, una riga per prodotto, ogni riga sara' colonna del DataFrame di output. Possono essere sia i valori di input che quelli di output\n",
        "   -label: nome delle colonne del DataFrame\n",
        "   -shift(default=0): shift temporale. Le prime righe del DataFrame saranno shiftate da 'shift' righe che valgono 0. Lo shift e' temporale e serve per allineare/ritardare input e target\n",
        "  OUTPUT\n",
        "   -df: DataFrame che contiene i valori letti da $filename e riorganizzati\n",
        "  \"\"\"\n",
        "  print(f\"reading data shift: {str(shift)}\")\n",
        "  with open(filename,'rb') as f:\n",
        "    for i, line in enumerate(f):\n",
        "      tmp_line = line.decode('utf-8')\n",
        "      tmp_values = [int(i) for i in tmp_line.strip().split(';') if i != '']\n",
        "      shift_step = shift if shift is not 0 else None\n",
        "      if shift_step is not None:\n",
        "        tmp_head = [0 for _ in range(shift)]\n",
        "        tmp_tail = tmp_values[:-shift]\n",
        "        tmp_values = tmp_head + tmp_tail\n",
        "      if i == 0:\n",
        "        df = pd.DataFrame(data=tmp_values, columns=[\"{}\".format(label[i])])\n",
        "      df[\"{}\".format(label[i])] = tmp_values\n",
        "  print(\"Created DataFrame shape: {}\".format(df.shape))\n",
        "  return df"
      ],
      "metadata": {
        "id": "lw9X60zJERPJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_and_fit(model, window, patience=2):\n",
        "  '''\n",
        "  funzione per istanziare il modello e addestrarlo\n",
        "  INPUT\n",
        "   -model: modello tensorflow\n",
        "   -window: oggetto per generare le finestre di dati\n",
        "   -patiente(defaul=2): criterio per early stopping\n",
        "  OUTPUT\n",
        "   -history: modello addestrato\n",
        "  ''' \n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train,\n",
        "                      epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val)\n",
        "  return history"
      ],
      "metadata": {
        "id": "9EVcmQOPv9ka"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Caricamento e analisi dei dati**"
      ],
      "metadata": {
        "id": "3PUKy7XuHiIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo il numero di prodotti e i nomi delle colonne del DataFrame di INPUT e TARGET "
      ],
      "metadata": {
        "id": "TR4ySMxi62ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_PRODS = 20\n",
        "INPUT_LABELS = [f\"prod_{i}\" for i in range(N_PRODS)]\n",
        "TARGET_LABELS = [f\"target_{i}\" for i in range(N_PRODS)]"
      ],
      "metadata": {
        "id": "KfCk1syQHpbH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_X = read_XY(\"X.txt\",INPUT_LABELS,shift=0)\n",
        "data_Y = read_XY(\"Y.txt\",TARGET_LABELS,shift=1)\n",
        "\n",
        "#DataFrame che unisce in un'unica tabella INPUT e OUTPUT\n",
        "df = data_X.join(data_Y)\n",
        "\n",
        "print(f\"Numero di prodotti: {str(df.shape[1])}\")\n",
        "print(f\"Numero di istanti temporali: {str(df.shape[0])}\")"
      ],
      "metadata": {
        "id": "IWCza62pAXMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osservare le prime righe del DataFrame"
      ],
      "metadata": {
        "id": "yrfLcPJt8A9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zKdiKeWX84jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vedere le statistiche di ciacun prodotto/target nel DataFrame"
      ],
      "metadata": {
        "id": "XCwvAi6L79xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().transpose()"
      ],
      "metadata": {
        "id": "ukFaMxaM_8nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crea paritizion di train, val, dev\n",
        "\n",
        "#Percentuale di suddivisione tra Train/Valid/Test (devono sommare a 1)\n",
        "split_partition = [70,20,10]\n",
        "\n",
        "\n",
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*split_partition[0]/100)]\n",
        "val_df = df[int(n*split_partition[0]/100):int(n*(split_partition[0]+split_partition[1])/100)]\n",
        "test_df = df[int(n*(split_partition[0]+split_partition[1])/100):]\n",
        "\n",
        "num_features = int(df.shape[1]/2)\n",
        "num_products = int(df.shape[1]/2)\n",
        "print(f\"Numero di prodotti(input): {num_features}\")\n",
        "print(f\"Numero di prodotti(target): {num_products}\")\n",
        "print(f\"Numero esempi totali: {len(df)}\")\n",
        "print(f\"Numero esempi train: {train_df.shape[0]}\")\n",
        "print(f\"Numero esempi val: {val_df.shape[0]}\")\n",
        "print(f\"Numero esempi test: {test_df.shape[0]}\")"
      ],
      "metadata": {
        "id": "eBTLGBNC_8rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcoliamo ora il vettore di normalizzazione in base ai valori di training e poi normalizziamo i dataset di train/valid/test"
      ],
      "metadata": {
        "id": "B2H6GycY8XFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizzare i valori\n",
        "train_max = train_df.max()\n",
        "\n",
        "train_df = train_df / train_max\n",
        "val_df = val_df / train_max\n",
        "test_df = test_df / train_max"
      ],
      "metadata": {
        "id": "7zDdZeWZEfZC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Definizione e addestramento del modello**"
      ],
      "metadata": {
        "id": "JLpnpz4jwB24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo i parametri per l'addestramento del modello e la definizione delle finestre di dati.\n",
        "\n",
        "*   MAX_EPOCHS: numero massimo di epoche\n",
        "*   INPUT_time_STEP: finestra di input (quanti istanti t uso prima di generare output)\n",
        "*   OUT_STEPS: finestra di output (quanti istanti temporali t di target voglio generare, nel nostro caso 1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cfRSAQVp8125"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurazione\n",
        "MAX_EPOCHS = 20\n",
        "INPUT_time_STEP=7\n",
        "OUT_STEPS=1"
      ],
      "metadata": {
        "id": "0S4A1y1VAYRP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo la Classe `multi_window` per generare le finestre di dati"
      ],
      "metadata": {
        "id": "zKbYMEcO-RNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_window = WindowGenerator(input_width=INPUT_time_STEP,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               train_df=train_df,\n",
        "                               val_df=val_df,\n",
        "                               test_df=test_df,\n",
        "                               input_columns=[f\"prod_{i}\" for i in range(num_products)],\n",
        "                               label_columns=[f\"target_{i}\" for i in range(num_products)])\n",
        "print(multi_window)"
      ],
      "metadata": {
        "id": "FTDf-eDBv9ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo il modello `lstm_model` che ha\n",
        "\n",
        "\n",
        "*   Layer LSTM di dimensione 32\n",
        "*   Layer Dense di dimensione 50 (act='relu')\n",
        "*   Layer Dense di output (output=numero di prodotti, funzione di attivazione relu per avere solo valori positivi)\n",
        "\n"
      ],
      "metadata": {
        "id": "FtY5OIza-sQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(50),\n",
        "    tf.keras.layers.Dense(units=num_products, activation='relu')\n",
        "])"
      ],
      "metadata": {
        "id": "bSa8D1SMv9su"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istanziamo e addestriamo il modello"
      ],
      "metadata": {
        "id": "omEz0Z95_Mlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = compile_and_fit(lstm_model, multi_window)"
      ],
      "metadata": {
        "id": "6SWXq-Ugv9yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizziamo un riassunto dell'architettura del modello"
      ],
      "metadata": {
        "id": "oZN0SLqp8hzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()"
      ],
      "metadata": {
        "id": "QvgPiZoM2Ecr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valutiamo le performance in test (ma e' fatto alle stesse condizioni del training, quindi con la stessa finestra temporale, e quindi poco utile).\n",
        "\n",
        "Nella sezione successiva si implementa una pipeline di test migliore e piu' flessibile."
      ],
      "metadata": {
        "id": "UG1MlDzh_cVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tf_test = lstm_model.evaluate(multi_window.test)"
      ],
      "metadata": {
        "id": "XE-NawSGBKoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test**"
      ],
      "metadata": {
        "id": "jeDSA4Ni9hcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questa pipeline di test e' costruita per generare i valori degli ultimi frame temporali del DataFrame `df` inserendo anche uno shfit temporale `time_step` quanti giorni prima utilizzo per crearmi il contesto.\n",
        "\n",
        "Venongo poi estatti anche i valori di target del test per misurare l'MSE.\n"
      ],
      "metadata": {
        "id": "uj6fR51o_2A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = 10\n",
        "norm_vector = train_max\n",
        "\n",
        "input_label_test_df = df[-len(test_df)-time_step:] / norm_vector\n",
        "input_label_test_df = input_label_test_df[INPUT_LABELS]\n",
        "target_label_test_df = df[TARGET_LABELS][-len(test_df):].to_numpy()"
      ],
      "metadata": {
        "id": "twIFVmSy3vpp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I valori di output del modello sono gia' normalizzati"
      ],
      "metadata": {
        "id": "soDDmtoUvFDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test(input_label_test_df, 'output_32_50_test_10', lstm_model, norm_vector, time_step=time_step)"
      ],
      "metadata": {
        "id": "EK1MZ_ZQINJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77510679-53de-451a-fa56-66f21462c23f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di prodotti: 20\n",
            "Numero di output da generare: 86\n",
            "Output filename: output_32_50_test_10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mse('output_32_50_test_10',target_label_test_df)"
      ],
      "metadata": {
        "id": "XKYMQA9IEodu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_avg_mse('mse_avg_output_32_50_test_10')"
      ],
      "metadata": {
        "id": "2yamoUZeG95w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247f620e-f1b6-4f4c-a174-cc0d230c8cc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.119061617157648"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Salvare e Caricare il modello**"
      ],
      "metadata": {
        "id": "up5BlbeV_1GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa sezione vediamo come salavare un modello addestrato per poi inseguito caricarlo.\n",
        "\n",
        "Ricordiamo che in un modello di Rete Neurale non è solo importante il valore dei pesi (le matrici), ma anche il grafo computazionale delle operazioni, percioà nella cartella in cui salveremo il modello 'MODEL_PATH', la struttura dati al suo interno è complessa."
      ],
      "metadata": {
        "id": "jX2F3F3cB180"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH='model'\n",
        "lstm_model.save(MODEL_PATH)"
      ],
      "metadata": {
        "id": "xKVDHHZO_7Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vediamo ora come si carica un modello salvato: verrà ricostruitio il modello con pesi addestrati e grafo."
      ],
      "metadata": {
        "id": "_nJz7HwCCt-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)"
      ],
      "metadata": {
        "id": "lIswXeM1ABGL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcoliamo l'output del modello appena caricato, quando poi andremo a confrontare làoutput di questo modello con quello generato dal modello salvato ci aspetteremo che i due file coincidano. "
      ],
      "metadata": {
        "id": "kIoNmLsEC8Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test(input_label_test_df, 'output_reconstructed', reconstructed_model, norm_vector, time_step=time_step)"
      ],
      "metadata": {
        "id": "7m-47EnfAWe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!diff output_32_50_test_10 output_reconstructed"
      ],
      "metadata": {
        "id": "tybjJ6-MAfbF"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}